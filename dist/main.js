/*
THIS IS A GENERATED/BUNDLED FILE BY ESBUILD
If you want to view the source, please visit the github repository of this plugin
*/

"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);

// main.ts
var main_exports = {};
__export(main_exports, {
  default: () => GranolaNotesPlugin
});
module.exports = __toCommonJS(main_exports);
var import_obsidian4 = require("obsidian");

// GranolaSettings.ts
var import_obsidian = require("obsidian");
var DEFAULT_SETTINGS = {
  audioFolder: "attachments/granola_audio",
  whisperModel: "base.en",
  whisperLanguage: "en",
  llmEndpoint: "http://localhost:11434/api/generate",
  templateFolder: "granola-templates",
  aiModel: "mistral",
  aiTemperature: 0.7,
  enableDualTrack: true,
  defaultMicDevice: "",
  defaultSystemDevice: "",
  autoInsertTimestamp: true,
  autoTranscribeOnEnd: true,
  showStatusBar: true
};
var GranolaSettingsTab = class extends import_obsidian.PluginSettingTab {
  constructor(app, plugin) {
    super(app, plugin);
    this.plugin = plugin;
  }
  display() {
    const { containerEl } = this;
    containerEl.empty();
    containerEl.createEl("h2", { text: "Granola Notes Settings" });
    new import_obsidian.Setting(containerEl).setName("Audio Folder").setDesc("Where to save meeting audio files").addText((text) => text.setPlaceholder("attachments/granola_audio").setValue(this.plugin.settings.audioFolder).onChange(async (value) => {
      this.plugin.settings.audioFolder = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Whisper Model").setDesc("Model to use for transcription (e.g., base.en, small.en)").addText((text) => text.setPlaceholder("base.en").setValue(this.plugin.settings.whisperModel).onChange(async (value) => {
      this.plugin.settings.whisperModel = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Whisper Language").setDesc("Language code for transcription (e.g., en, es)").addText((text) => text.setPlaceholder("en").setValue(this.plugin.settings.whisperLanguage).onChange(async (value) => {
      this.plugin.settings.whisperLanguage = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("LLM Endpoint").setDesc("URL for AI summary/action items (Ollama/OpenAI)").addText((text) => text.setPlaceholder("http://localhost:11434/api/generate").setValue(this.plugin.settings.llmEndpoint).onChange(async (value) => {
      this.plugin.settings.llmEndpoint = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("AI Model").setDesc("Model to use for AI (e.g., mistral, llama2, gpt-3.5-turbo)").addText((text) => text.setPlaceholder("mistral").setValue(this.plugin.settings.aiModel).onChange(async (value) => {
      this.plugin.settings.aiModel = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("AI Temperature").setDesc("Creativity for AI (0.0 = deterministic, 1.0 = creative)").addSlider((slider) => slider.setLimits(0, 1, 0.01).setValue(this.plugin.settings.aiTemperature).onChange(async (value) => {
      this.plugin.settings.aiTemperature = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Template Folder").setDesc("Folder for meeting note templates").addText((text) => text.setPlaceholder("granola-templates").setValue(this.plugin.settings.templateFolder).onChange(async (value) => {
      this.plugin.settings.templateFolder = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Enable Dual-Track Recording").setDesc("Record mic and system audio separately (macOS only)").addToggle((toggle) => toggle.setValue(this.plugin.settings.enableDualTrack).onChange(async (value) => {
      this.plugin.settings.enableDualTrack = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Default Mic Device").setDesc("Default microphone input device name").addText((text) => text.setPlaceholder("MacBook Pro Microphone").setValue(this.plugin.settings.defaultMicDevice).onChange(async (value) => {
      this.plugin.settings.defaultMicDevice = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Default System Device").setDesc("Default system audio device name (e.g., BlackHole)").addText((text) => text.setPlaceholder("BlackHole 2ch").setValue(this.plugin.settings.defaultSystemDevice).onChange(async (value) => {
      this.plugin.settings.defaultSystemDevice = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Auto-Insert Timestamp").setDesc("Automatically insert timestamp with each note").addToggle((toggle) => toggle.setValue(this.plugin.settings.autoInsertTimestamp).onChange(async (value) => {
      this.plugin.settings.autoInsertTimestamp = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Auto-Transcribe on End").setDesc("Automatically transcribe and summarize when ending meeting").addToggle((toggle) => toggle.setValue(this.plugin.settings.autoTranscribeOnEnd).onChange(async (value) => {
      this.plugin.settings.autoTranscribeOnEnd = value;
      await this.plugin.saveSettings();
    }));
    new import_obsidian.Setting(containerEl).setName("Show Status Bar").setDesc("Show meeting status and controls in the status bar").addToggle((toggle) => toggle.setValue(this.plugin.settings.showStatusBar).onChange(async (value) => {
      this.plugin.settings.showStatusBar = value;
      await this.plugin.saveSettings();
    }));
  }
};

// MeetingSession.ts
var import_obsidian2 = require("obsidian");
var MeetingSession = class {
  constructor(audioRecorder, transcriber, aiGenerator, app, settings) {
    this.title = "";
    this.audioFilePath = "";
    this.systemFilePath = "";
    this.notePath = "";
    this.startTime = Date.now();
    this.audioRecorder = audioRecorder;
    this.transcriber = transcriber;
    this.aiGenerator = aiGenerator;
    this.app = app;
    this.vault = app?.vault;
    this.settings = settings || DEFAULT_SETTINGS;
    console.log("[Granola] MeetingSession constructed", { hasApp: !!app, settings: this.settings });
  }
  /**
   * Create a new note from a template, replacing variables.
   *
   * If the template is not set, not found, or empty, creates a minimal default note.
   *
   * Args:
   *   title (string): Meeting title.
   *   template (string): Template name (optional).
   *   audioPath (string): Path to meeting audio file.
   *
   * Returns:
   *   Promise<string>: Path to the created note.
   */
  async createNoteFromTemplate(title, template, audioPath) {
    if (!this.app || !this.vault) {
      new import_obsidian2.Notice("Granola: Obsidian app context required to create note.");
      console.error("[Granola] Cannot create note: missing app or vault context");
      throw new Error("Obsidian app context required");
    }
    const templatesFolder = this.settings.templateFolder || "granola-templates";
    let templateContent = "";
    let usedTemplate = false;
    if (template && template.trim() !== "") {
      try {
        const folder = this.vault.getAbstractFileByPath(templatesFolder);
        if (folder && folder instanceof import_obsidian2.TFolder) {
          const file = folder.children.find((f) => f instanceof import_obsidian2.TFile && f.name === `${template}.md`);
          if (file && file instanceof import_obsidian2.TFile) {
            templateContent = await this.vault.read(file);
            usedTemplate = true;
            console.log("[Granola] Loaded template:", template);
          }
        }
        if (!templateContent) {
          new import_obsidian2.Notice(`Granola: Template '${template}' not found or empty. Using default note structure.`);
          console.warn(`[Granola] Template '${template}' not found or empty. Using default.`);
        }
      } catch (e) {
        new import_obsidian2.Notice(`Granola: Error loading template. Using default note structure.`);
        console.error("[Granola] Error loading template:", e);
      }
    }
    if (!usedTemplate || !templateContent) {
      templateContent = `# ${title}

- Date: {{date}}
- Audio: {{audio_file_path}}

## Notes

## Transcript

## Summary (AI)

## Action Items

## Follow-up Email
`;
      console.log("[Granola] Using default note structure");
    }
    const dateStr = window.moment ? window.moment(this.startTime).format("YYYY-MM-DD HH:mm") : new Date(this.startTime).toISOString();
    const noteContent = templateContent.replace(/{{title}}/g, title).replace(/{{date}}/g, dateStr).replace(/{{audio_file_path}}/g, audioPath);
    const notePath = `Granola Meetings/${dateStr.replace(/[: ]/g, "-")}_${title.replace(/\s+/g, "_")}.md`;
    const normalizedPath = (0, import_obsidian2.normalizePath)(notePath);
    const parentFolderPath = normalizedPath.split("/").slice(0, -1).join("/");
    try {
      let folder = this.vault.getAbstractFileByPath(parentFolderPath);
      if (!folder) {
        console.log("[Granola] Parent folder does not exist, creating:", parentFolderPath);
        await this.vault.createFolder(parentFolderPath);
      }
      await this.vault.create(normalizedPath, noteContent);
      console.log("[Granola] Note created at", normalizedPath);
    } catch (e) {
      new import_obsidian2.Notice(`Granola: Failed to create note at ${normalizedPath}`);
      console.error("[Granola] Failed to create note:", e, "Path:", normalizedPath, "Parent:", parentFolderPath);
      throw e;
    }
    this.notePath = normalizedPath;
    return normalizedPath;
  }
  /**
   * Add a timestamped note to the session note under the ## Notes section.
   */
  async addTimestampedNote(text) {
    if (!this.vault || !this.notePath) {
      new import_obsidian2.Notice("Granola: Cannot add note, missing vault or note path.");
      console.error("[Granola] Cannot add timestamped note: missing vault or notePath");
      return;
    }
    const file = this.vault.getAbstractFileByPath(this.notePath);
    if (!file || !(file instanceof import_obsidian2.TFile)) {
      new import_obsidian2.Notice("Granola: Session note file not found.");
      console.error("[Granola] Session note file not found:", this.notePath);
      return;
    }
    let noteLine = text;
    if (this.settings.autoInsertTimestamp) {
      const elapsed = Math.floor((Date.now() - this.startTime) / 1e3);
      const hh = String(Math.floor(elapsed / 3600)).padStart(2, "0");
      const mm = String(Math.floor(elapsed % 3600 / 60)).padStart(2, "0");
      const ss = String(elapsed % 60).padStart(2, "0");
      const timestamp = `[${hh}:${mm}:${ss}]`;
      noteLine = `${timestamp} ${text}`;
    }
    let content = await this.vault.read(file);
    const notesSection = content.match(/^## Notes[\s\S]*?(?=^## |---|$)/m);
    if (notesSection) {
      const idx = content.indexOf(notesSection[0]) + notesSection[0].length;
      content = content.slice(0, idx) + `
${noteLine}` + content.slice(idx);
      console.log("[Granola] Timestamped note added to ## Notes section");
    } else {
      content += `

${noteLine}`;
      new import_obsidian2.Notice("Granola: ## Notes section not found, appending note at end.");
      console.warn("[Granola] ## Notes section not found, appended at end");
    }
    await this.vault.modify(file, content);
  }
  /**
   * Start a new meeting session: create note, start audio recording.
   */
  async start(title, template, micDevice, systemDevice, basePath) {
    this.title = title;
    try {
      await this.audioRecorder.startRecording(
        micDevice,
        this.settings.enableDualTrack ? systemDevice : "",
        basePath
      );
      console.log("[Granola] Audio recording started", { micDevice, systemDevice, basePath });
    } catch (e) {
      new import_obsidian2.Notice("Granola: Error starting audio recording.");
      console.error("[Granola] Error starting audio recording:", e);
    }
    this.audioFilePath = this.audioRecorder.micFilePath;
    this.systemFilePath = this.audioRecorder.systemFilePath;
    if (this.app) {
      try {
        await this.createNoteFromTemplate(title, template, this.audioFilePath);
      } catch (e) {
        new import_obsidian2.Notice("Granola: Error creating note from template.");
        console.error("[Granola] Error creating note from template:", e);
      }
    }
  }
  /**
   * End the meeting session: stop audio, transcribe, generate AI summary, and update the note.
   */
  async end(language) {
    if (!this.vault || !this.notePath) {
      new import_obsidian2.Notice("Granola: Cannot end session, vault or note path missing.");
      console.error("[Granola] Cannot end session: missing vault or notePath");
      return;
    }
    const file = this.vault.getAbstractFileByPath(this.notePath);
    if (!file || !(file instanceof import_obsidian2.TFile)) {
      new import_obsidian2.Notice("Granola: Session note file not found.");
      console.error("[Granola] Session note file not found:", this.notePath);
      return;
    }
    try {
      await this.audioRecorder.stopRecording();
      console.log("[Granola] Audio recording stopped");
    } catch (e) {
      new import_obsidian2.Notice("Granola: Error stopping audio recording.");
      console.error("[Granola] Error stopping audio recording:", e);
    }
    let transcript = "";
    if (this.settings.autoTranscribeOnEnd) {
      try {
        transcript = await this.transcriber.transcribeDualTracks(this.audioFilePath, this.systemFilePath, this.settings.whisperLanguage || language);
        console.log("[Granola] Transcription complete");
      } catch (e) {
        new import_obsidian2.Notice("Granola: Error during transcription.");
        console.error("[Granola] Error during transcription:", e);
      }
    }
    let aiResults = { summary: "", actionItems: "", followupEmail: "" };
    try {
      const notes = "";
      aiResults = await this.aiGenerator.generateSummary(notes, transcript);
      console.log("[Granola] AI summary generated");
    } catch (e) {
      new import_obsidian2.Notice("Granola: Error generating AI summary.");
      console.error("[Granola] Error generating AI summary:", e);
    }
    let content = await this.vault.read(file);
    content = this._replaceSection(content, "Transcript", transcript);
    content = this._replaceSection(content, "Summary (AI)", aiResults.summary);
    content = this._replaceSection(content, "Action Items", aiResults.actionItems);
    content = this._replaceSection(content, "Follow-up Email", aiResults.followupEmail);
    await this.vault.modify(file, content);
    new import_obsidian2.Notice("Granola: Meeting session ended and note updated.");
    console.log("[Granola] Meeting session ended and note updated");
  }
  /**
   * Replace the content under a given markdown section header.
   */
  _replaceSection(content, section, newText) {
    const regex = new RegExp(`(^## ${section}\\s*$)([\\s\\S]*?)(?=^## |---|$)`, "m");
    if (regex.test(content)) {
      return content.replace(regex, `$1
${newText}
`);
    } else {
      return content + `

## ${section}
${newText}
`;
    }
  }
};

// AudioRecorder.ts
var import_child_process = require("child_process");
var AudioRecorder = class {
  constructor(settings) {
    this.micFilePath = "";
    this.systemFilePath = "";
    this.process = null;
    this.settings = settings || DEFAULT_SETTINGS;
    console.log("[Granola] AudioRecorder constructed", { settings: this.settings });
  }
  /**
   * Start recording mic and (optionally) system audio to separate files (macOS only).
   * Uses settings.enableDualTrack to determine if system audio is recorded.
   *
   * Args:
   *   micDevice (string): Name of mic input device (e.g., 'MacBook Pro Microphone').
   *   systemDevice (string): Name of system audio device (e.g., 'BlackHole 2ch').
   *   basePath (string): Base path for output files.
   */
  async startRecording(micDevice, systemDevice, basePath) {
    this.micFilePath = `${basePath}_mic.wav`;
    this.systemFilePath = `${basePath}_system.wav`;
    console.log("[Granola] startRecording called", { micDevice, systemDevice, basePath });
    const fs = require("fs");
    const path = require("path");
    const outDir = path.dirname(this.micFilePath);
    if (!fs.existsSync(outDir)) {
      fs.mkdirSync(outDir, { recursive: true });
      console.log("[Granola] Created audio output directory:", outDir);
    }
    if (this.settings.enableDualTrack && systemDevice) {
      const ffmpegArgs = [
        "-y",
        "-f",
        "avfoundation",
        "-i",
        `${micDevice}:none`,
        "-f",
        "avfoundation",
        "-i",
        `none:${systemDevice}`,
        "-map",
        "0:a",
        this.micFilePath,
        "-map",
        "1:a",
        this.systemFilePath
      ];
      console.log("[Granola] Starting dual-track ffmpeg:", "ffmpeg", ffmpegArgs.join(" "));
      this.process = (0, import_child_process.spawn)("ffmpeg", ffmpegArgs);
    } else {
      const ffmpegArgs = [
        "-y",
        "-f",
        "avfoundation",
        "-i",
        micDevice,
        this.micFilePath
      ];
      console.log("[Granola] Starting single-track ffmpeg:", "ffmpeg", ffmpegArgs.join(" "));
      this.process = (0, import_child_process.spawn)("ffmpeg", ffmpegArgs);
    }
    if (this.process) {
      if (this.process.stdout) {
        this.process.stdout.on("data", (data) => {
          console.log(`[Granola] ffmpeg stdout: ${data}`);
        });
      }
      if (this.process.stderr) {
        this.process.stderr.on("data", (data) => {
          console.log(`[Granola] ffmpeg stderr: ${data}`);
        });
      }
      this.process.on("error", (err) => {
        console.error("[Granola] ffmpeg process error:", err);
      });
      this.process.on("exit", (code, signal) => {
        console.log(`[Granola] ffmpeg exited with code ${code}, signal ${signal}`);
      });
    } else {
      throw new Error("Failed to start ffmpeg process");
    }
  }
  /**
   * Stop recording audio.
   */
  async stopRecording() {
    if (this.process) {
      this.process.kill("SIGINT");
      console.log("[Granola] stopRecording called, ffmpeg process killed");
      this.process = null;
    } else {
      console.warn("[Granola] stopRecording called, but no ffmpeg process was running");
    }
  }
};

// Transcriber.ts
var Transcriber = class {
  constructor(whisperPath, modelPath) {
    this.whisperPath = whisperPath;
    this.modelPath = modelPath;
    console.log("[Granola] Transcriber constructed", { whisperPath, modelPath });
  }
  /**
   * Transcribe a single audio file using Whisper.cpp.
   *
   * Args:
   *   audioPath (string): Path to .wav file.
   *   language (string): Language code (e.g., 'en').
   *   outputPath (string): Path to save transcript.
   *
   * Returns:
   *   Promise<string>: Transcript text.
   */
  async transcribeFile(audioPath, language, outputPath) {
    console.log("[Granola] transcribeFile called", { audioPath, language, outputPath });
    return "";
  }
  /**
   * Transcribe both mic and system audio, merge with speaker labels.
   *
   * Args:
   *   micPath (string): Path to mic audio file.
   *   systemPath (string): Path to system audio file.
   *   language (string): Language code.
   *
   * Returns:
   *   Promise<string>: Merged transcript with speaker labels.
   */
  async transcribeDualTracks(micPath, systemPath, language) {
    console.log("[Granola] transcribeDualTracks called", { micPath, systemPath, language });
    const micTranscript = await this.transcribeFile(micPath, language, micPath + ".txt");
    const systemTranscript = await this.transcribeFile(systemPath, language, systemPath + ".txt");
    console.log("[Granola] Dual-track transcription complete");
    return `You:
${micTranscript}
Other:
${systemTranscript}`;
  }
};

// AIGenerator.ts
var AIGenerator = class {
  constructor(endpoint, model, fallbackEndpoint, fallbackModel) {
    this.endpoint = endpoint;
    this.model = model;
    this.fallbackEndpoint = fallbackEndpoint;
    this.fallbackModel = fallbackModel;
    console.log("[Granola] AIGenerator constructed", { endpoint, model, fallbackEndpoint, fallbackModel });
  }
  /**
   * Generate AI summary, action items, and follow-up email from notes and transcript.
   *
   * Args:
   *   notes (string): Meeting notes.
   *   transcript (string): Full transcript text.
   *
   * Returns:
   *   Promise<{ summary: string; actionItems: string; followupEmail: string; }>
   */
  async generateSummary(notes, transcript) {
    const prompt = `You are an expert meeting assistant.

Your task is to analyze the provided meeting notes and transcript, then respond ONLY with a valid JSON object containing the following keys: summary, actionItems, followupEmail.

Requirements:
- summary: A concise summary of the meeting.
- actionItems: A bullet list of actionable tasks.
- followupEmail: A draft follow-up email to send to participants.

If you are unsure, return empty strings for any field.

Meeting Notes:
${notes}

Transcript:
${transcript}

Respond ONLY with a JSON object, no explanations or extra text.`;
    const callLLM = async (endpoint, model) => {
      console.log("[Granola] Calling LLM API:", endpoint);
      const res = await fetch(endpoint, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ model, prompt, stream: false })
      });
      if (!res.ok) {
        console.error("[Granola] LLM API error:", res.status, endpoint);
        throw new Error(`LLM API error: ${res.status}`);
      }
      const data = await res.json();
      let parsed;
      try {
        parsed = JSON.parse(data.response);
      } catch (e) {
        const match = data.response.match(/\{[\s\S]*\}/);
        if (match)
          parsed = JSON.parse(match[0]);
        else {
          console.error("[Granola] Could not parse LLM response as JSON:", data.response);
          throw new Error("Could not parse LLM response as JSON");
        }
      }
      return {
        summary: parsed.summary || "",
        actionItems: parsed.actionItems || "",
        followupEmail: parsed.followupEmail || ""
      };
    };
    try {
      const result = await callLLM(this.endpoint, this.model);
      console.log("[Granola] LLM summary generated successfully");
      return result;
    } catch (err) {
      console.error("[Granola] Primary LLM failed:", err);
      if (this.fallbackEndpoint && this.fallbackModel) {
        try {
          const fallbackResult = await callLLM(this.fallbackEndpoint, this.fallbackModel);
          console.log("[Granola] Fallback LLM summary generated successfully");
          return fallbackResult;
        } catch (fallbackErr) {
          console.error("[Granola] Fallback LLM also failed:", fallbackErr);
        }
      }
      console.log("[Granola] All LLM attempts failed, returning empty summary");
      return { summary: "", actionItems: "", followupEmail: "" };
    }
  }
};

// GranolaMeetingModal.ts
var import_obsidian3 = require("obsidian");
var GranolaMeetingModal = class extends import_obsidian3.Modal {
  constructor(app, templates, micDevices, systemDevices, onSubmit) {
    super(app);
    this.result = {
      title: "",
      template: "",
      micDevice: "",
      systemDevice: "",
      confirmed: false
    };
    this.templates = templates;
    this.micDevices = micDevices;
    this.systemDevices = systemDevices;
    this.onSubmit = onSubmit;
  }
  onOpen() {
    const { contentEl } = this;
    contentEl.empty();
    contentEl.createEl("h2", { text: "Start New Meeting" });
    new import_obsidian3.Setting(contentEl).setName("Meeting Title").addText((text) => {
      text.setPlaceholder("Enter meeting title...").onChange((value) => this.result.title = value);
    });
    new import_obsidian3.Setting(contentEl).setName("Template").addDropdown((dropdown) => {
      this.templates.forEach((t) => dropdown.addOption(t, t));
      dropdown.onChange((value) => this.result.template = value);
      if (this.templates.length > 0)
        dropdown.setValue(this.templates[0]);
    });
    new import_obsidian3.Setting(contentEl).setName("Microphone Device").addDropdown((dropdown) => {
      this.micDevices.forEach((d) => dropdown.addOption(d, d));
      dropdown.onChange((value) => this.result.micDevice = value);
      if (this.micDevices.length > 0)
        dropdown.setValue(this.micDevices[0]);
    });
    new import_obsidian3.Setting(contentEl).setName("System Audio Device").addDropdown((dropdown) => {
      this.systemDevices.forEach((d) => dropdown.addOption(d, d));
      dropdown.onChange((value) => this.result.systemDevice = value);
      if (this.systemDevices.length > 0)
        dropdown.setValue(this.systemDevices[0]);
    });
    new import_obsidian3.Setting(contentEl).addButton((btn) => {
      btn.setButtonText("Start Meeting").setCta().onClick(() => {
        this.result.confirmed = true;
        this.close();
      });
    });
  }
  onClose() {
    this.onSubmit(this.result);
    this.contentEl.empty();
  }
};

// main.ts
var GranolaNotesPlugin = class extends import_obsidian4.Plugin {
  constructor() {
    super(...arguments);
    // Definite assignment assertion
    this.session = null;
    this.statusBarEl = null;
  }
  async onload() {
    console.log("[Granola] Plugin loading...");
    this.settings = Object.assign({}, DEFAULT_SETTINGS, await this.loadData());
    console.log("[Granola] Settings loaded:", this.settings);
    this.addSettingTab(new GranolaSettingsTab(this.app, this));
    console.log("[Granola] Settings tab registered");
    this.addCommand({
      id: "granola-toggle-meeting",
      name: "Granola: Start/Stop Meeting (Toggle)",
      callback: async () => {
        if (this.session) {
          try {
            await this.session.end(this.settings.whisperLanguage || "en");
            new import_obsidian4.Notice("Granola: Meeting session stopped");
            this.showStatusBar("Meeting stopped");
          } catch (err) {
            console.error("[Granola] Error stopping meeting session:", err);
            new import_obsidian4.Notice("Granola: Failed to stop meeting session.");
          }
          this.session = null;
          return;
        }
        const templatesFolder = this.settings.templateFolder;
        let templates = [];
        try {
          const folder = this.app.vault.getAbstractFileByPath(templatesFolder);
          if (folder && folder instanceof import_obsidian4.TFolder) {
            templates = folder.children.filter((f) => f instanceof import_obsidian4.TFile).map((f) => f.basename);
          }
        } catch (e) {
          console.warn("[Granola] Error loading templates folder:", e);
          templates = ["default"];
        }
        if (templates.length === 0)
          templates = ["default"];
        const micDevices = this.settings.defaultMicDevice ? [this.settings.defaultMicDevice] : ["MacBook Pro Microphone"];
        const systemDevices = this.settings.defaultSystemDevice ? [this.settings.defaultSystemDevice] : ["BlackHole 2ch"];
        new GranolaMeetingModal(this.app, templates, micDevices, systemDevices, async (result) => {
          if (!result.confirmed)
            return;
          const { title, template, micDevice, systemDevice } = result;
          const basePath = `${this.settings.audioFolder}/${Date.now()}_${title.replace(/\s+/g, "_")}`;
          const audioRecorder = new AudioRecorder(this.settings);
          const transcriber = new Transcriber("path/to/whisper.cpp", this.settings.whisperModel);
          const aiGenerator = new AIGenerator(this.settings.llmEndpoint, this.settings.aiModel);
          this.session = new MeetingSession(audioRecorder, transcriber, aiGenerator, this.app, this.settings);
          try {
            await this.session.start(
              title,
              template,
              micDevice || this.settings.defaultMicDevice,
              systemDevice || this.settings.defaultSystemDevice,
              basePath
            );
            console.log("[Granola] Meeting session started:", { title, template, micDevice, systemDevice, basePath });
            new import_obsidian4.Notice("Granola: Meeting session started");
            this.showStatusBar("Meeting in progress...");
          } catch (err) {
            console.error("[Granola] Error starting meeting session:", err);
            new import_obsidian4.Notice("Granola: Failed to start meeting session.");
            this.session = null;
          }
        }).open();
      }
    });
    if (this.settings.showStatusBar) {
      this.showStatusBar("Ready for new meeting");
      console.log("[Granola] Status bar shown");
    }
    console.log("Granola Notes plugin loaded");
    console.log("[Granola] Plugin loaded successfully");
  }
  onunload() {
    this.hideStatusBar();
    console.log("Granola Notes plugin unloaded");
    console.log("[Granola] Plugin unloaded");
  }
  /**
   * Save plugin settings to disk.
   */
  async saveSettings() {
    await this.saveData(this.settings);
    console.log("[Granola] Settings saved:", this.settings);
    if (this.settings.showStatusBar) {
      this.showStatusBar("Ready for new meeting");
      console.log("[Granola] Status bar shown after settings save");
    } else {
      this.hideStatusBar();
      console.log("[Granola] Status bar hidden after settings save");
    }
  }
  /**
   * Show the status bar if enabled in settings.
   */
  showStatusBar(text) {
    if (!this.settings.showStatusBar) {
      this.hideStatusBar();
      console.log("[Granola] Tried to show status bar but disabled in settings");
      return;
    }
    if (!this.statusBarEl) {
      this.statusBarEl = this.addStatusBarItem();
      this.statusBarEl.classList.add("granola-status-bar");
      console.log("[Granola] Status bar element created");
    }
    this.statusBarEl.setText(text);
    console.log("[Granola] Status bar updated:", text);
  }
  /**
   * Hide the status bar and remove its element.
   */
  hideStatusBar() {
    if (this.statusBarEl) {
      this.statusBarEl.detach();
      this.statusBarEl = null;
      console.log("[Granola] Status bar element removed");
    }
  }
};
